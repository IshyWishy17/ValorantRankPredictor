{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e24c5f",
   "metadata": {},
   "source": [
    "Import the necessary libraries to scrape player stats. These include Selenium and BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff4b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e8c9b",
   "metadata": {},
   "source": [
    "Found a bunch of seed usernames, one from every rank. These will be needed to find other usernames/stats of players from the same rank(s)! Manually (yes, painstakingly) grabbed these usernames from here -  https://tracker.gg/valorant/lfg (Use the 'Rank' filter).\n",
    "\n",
    "Note that we only need a player's username (e.g. IshyWishy#7495) to scrape all their stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33611817",
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = [\n",
    "    'HabibiWasHere#8127',  # Iron 2\n",
    "    'choraprajett#S4tsu',  # Iron 3\n",
    "    'shaHIM#0911',         # Bronze 1\n",
    "    'roza#meow',           # Bronze 2\n",
    "    'hawaiiicattt#sigma',  # Bronze 3\n",
    "    'zezosk#6969',         # Silver 1\n",
    "    'Orgito29#ALBOZ',      # Silver 2\n",
    "    'yuuviix#TTV',         # Silver 3\n",
    "    'AllyThotti#999',      # Gold 1\n",
    "    'TabletOnly#LN7',      # Gold 2\n",
    "    'SinS Kalper#Kal16',   # Gold 3\n",
    "    'DANIELMERS#2505',     # Platinum 1\n",
    "    'StupidKaj#simp',      # Platinum 2\n",
    "    'LoserUri#momo',       # Platinum 3\n",
    "    'Kattu Poochi#Molly',  # Diamond 1\n",
    "    'Valkyzek#kydae',      # Diamond 2\n",
    "    'lia#εïз',             # Diamond 3\n",
    "    'Zheng#0511',          # Ascendant 1\n",
    "    'Nalapaya#UwU',        # Ascendant 2\n",
    "    'saranghae#666',       # Ascendant 3\n",
    "    'General#360zz',       # Immortal 1\n",
    "    'pierce#agne',         # Immortal 2\n",
    "    'Keem あ#1st',         # Immortal 3\n",
    "    'curry#lisa'           # Radiant\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b049d",
   "metadata": {},
   "source": [
    "These are the stat names that we are going to scrape. We won't be using all of them to predict a player's rank, but they are shown here for illustrative purposes, since we scrape all of them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9ca2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_names = ['Damage/Round', 'K/D Ratio', 'Headshot %', 'Win %',\\\n",
    "              'Wins', 'KAST', 'DDΔ/Round', 'Kills', 'Deaths', 'Assists',\\\n",
    "              'ACS', 'KAD Ratio', 'Kills/Round', 'First Bloods',\\\n",
    "              'Flawless Rounds', 'Aces']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c10ee1",
   "metadata": {},
   "source": [
    "Here is what a mini-scrape looks like! The scraped stats for 2 players have been printed. We also employ 2 utility functions to parse the soup and give us the required data in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aebbcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping HabibiWasHere#8127\n",
      "Iron 2 {'Damage/Round': '154.5', 'K/D Ratio': '1.12', 'Headshot %': '12.7%', 'Win %': '41.2%', 'Wins': '14', 'KAST': '71.8%', 'DDΔ/Round': '13', 'Kills': '574', 'Deaths': '512', 'Assists': '185', 'ACS': '240.6', 'KAD Ratio': '1.48', 'Kills/Round': '0.8', 'First Bloods': '88', 'Flawless Rounds': '21', 'Aces': '1'}\n",
      "\n",
      "Scraping choraprajett#S4tsu\n",
      "Iron 3 {'Damage/Round': '149.1', 'K/D Ratio': '1.03', 'Headshot %': '19.7%', 'Win %': '45.0%', 'Wins': '9', 'KAST': '71.6%', 'DDΔ/Round': '6', 'Kills': '317', 'Deaths': '307', 'Assists': '122', 'ACS': '221.2', 'KAD Ratio': '1.43', 'Kills/Round': '0.8', 'First Bloods': '19', 'Flawless Rounds': '19', 'Aces': '1'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import find_rank, find_highlighted_stats\n",
    "\n",
    "for username in usernames[:2]:\n",
    "    with webdriver.Chrome() as driver:\n",
    "        print(\"Scraping\", username)\n",
    "        # Scrape from '/overview'\n",
    "        driver.get(f\"https://tracker.gg/valorant/profile/riot/{username.replace('#', '%23')}/overview\")\n",
    "        page_source = driver.page_source\n",
    "    \n",
    "    # Parse HTML\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    rank = find_rank(soup)\n",
    "    others = find_highlighted_stats(soup)\n",
    "    print(rank, others)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be3f6b",
   "metadata": {},
   "source": [
    "Here's all the possible ranks that a player can belong to. A player must belong to exactly one rank at a given time. The ranks are sorted from lowest (Iron 1) to highest (Radiant).\n",
    "\n",
    "We intend on scraping the stats of exactly 5000 players per rank. We initialize rank_counts to all zeroes before we start our scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b96ca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iron 1': 0,\n",
       " 'Iron 2': 0,\n",
       " 'Iron 3': 0,\n",
       " 'Bronze 1': 0,\n",
       " 'Bronze 2': 0,\n",
       " 'Bronze 3': 0,\n",
       " 'Silver 1': 0,\n",
       " 'Silver 2': 0,\n",
       " 'Silver 3': 0,\n",
       " 'Gold 1': 0,\n",
       " 'Gold 2': 0,\n",
       " 'Gold 3': 0,\n",
       " 'Platinum 1': 0,\n",
       " 'Platinum 2': 0,\n",
       " 'Platinum 3': 0,\n",
       " 'Diamond 1': 0,\n",
       " 'Diamond 2': 0,\n",
       " 'Diamond 3': 0,\n",
       " 'Ascendant 1': 0,\n",
       " 'Ascendant 2': 0,\n",
       " 'Ascendant 3': 0,\n",
       " 'Immortal 1': 0,\n",
       " 'Immortal 2': 0,\n",
       " 'Immortal 3': 0,\n",
       " 'Radiant': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [\"Iron 1\", \"Iron 2\", \"Iron 3\",\\\n",
    "         \"Bronze 1\", \"Bronze 2\", \"Bronze 3\",\\\n",
    "         \"Silver 1\", \"Silver 2\", \"Silver 3\",\\\n",
    "         \"Gold 1\", \"Gold 2\", \"Gold 3\",\\\n",
    "         \"Platinum 1\", \"Platinum 2\", \"Platinum 3\",\\\n",
    "         \"Diamond 1\", \"Diamond 2\", \"Diamond 3\",\\\n",
    "         \"Ascendant 1\", \"Ascendant 2\", \"Ascendant 3\",\\\n",
    "         \"Immortal 1\", \"Immortal 2\", \"Immortal 3\",\\\n",
    "         \"Radiant\"]\n",
    "\n",
    "rank_counts = { rank: 0 for rank in ranks }\n",
    "rank_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339abc1a",
   "metadata": {},
   "source": [
    "We first write all the stat names on a single line in a new CSV file. This will serve as the row of column names, and will be useful for when we use pandas for visualization later. Run the cell block below only once, as it overwrites existing data (learnt this the hard way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fbf278",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stats.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(stat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded181c",
   "metadata": {},
   "source": [
    "Now that we have our stats CSV file ready to be populated, we begin our scraping. Our scraping strategy is this -\n",
    "We begin with our initial list of seed users, and scrape their stats one at a time. For each player, we then look at the first (most recent) match in their history and from there we obtain the names of 9 more players in similar ranks! Valorant is a 5v5 game and so each game has 10 players, which is what allows us to get the names of 9 more players per match. We look at only one match as this gives us enough players to continue BFS-ing on. Due to the matchmaking system of the game, each player is put in a game with people of similar ranks, allowing us to find more usernames per rank starting from a single username."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13c26",
   "metadata": {},
   "source": [
    "We first import an inbuilt queue module as our BFS data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7323cac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50a3be",
   "metadata": {},
   "source": [
    "Now we initialize a queue and add the list of seed users into the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4980423",
   "metadata": {},
   "outputs": [],
   "source": [
    "username_queue = queue.Queue()\n",
    "for username in usernames:\n",
    "    username_queue.put(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375c1f51",
   "metadata": {},
   "source": [
    "We define a helper function that scrapes 9 more usernames (players) by looking at one match of the given username. We make use of the '/matches' page for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a9b21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_usernames_from_match_history(username):\n",
    "    with webdriver.Chrome() as driver:\n",
    "        # Open the matches page\n",
    "        driver.get(f\"https://tracker.gg/valorant/profile/riot/{username.replace('#', '%23')}/matches\")\n",
    "        \n",
    "        # Put everything in a try block in case it fails, return an empty list (no more usernames) in this case\n",
    "        try:\n",
    "            # To get the first match details, we need to find the corresponding row and click on it\n",
    "            first_match_element = WebDriverWait(driver, 10).until(\\\n",
    "                      EC.visibility_of_element_located((By.XPATH, \"//div[contains(@class, 'vmr trn-match-row')]\")))\n",
    "            \n",
    "            # Clickable now\n",
    "            first_match_element.click()\n",
    "            \n",
    "            # Extract page source\n",
    "            page_source = driver.page_source\n",
    "            \n",
    "        except:\n",
    "            # Could not find more usernames :(\n",
    "            return []\n",
    "    \n",
    "    # Find usernames\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Find span tags that contain usernames\n",
    "    username_spans = soup.find_all('span', class_=lambda x: x and 'trn-ign__username fit-long-username' in x) \n",
    "    usernames = [span.text for span in username_spans]\n",
    "    \n",
    "    # Find span tags that contain the discriminator (part after (including) the #)\n",
    "    # For example, if IshyWishy#7495 is the full username, IshyWishy is the username and #7495 is the discriminator\n",
    "    discriminator_spans = soup.find_all('span', class_=lambda x: x and 'trn-ign__discriminator' in x) \n",
    "    discriminators = [span.text for span in discriminator_spans]\n",
    "    \n",
    "    # Combine usernames and discriminators to get the full username\n",
    "    usernames_with_disc = [usernames[i] + discriminators[i] for i in range(len(usernames))]\n",
    "    \n",
    "    return usernames_with_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552a463",
   "metadata": {},
   "source": [
    "Now that we have the helper/utility functions in place, let's start scraping! Remember, we keep going until we have exactly 5000 players from every rank!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed2937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import write_to_stats_csv\n",
    "\n",
    "def scrape_stats():\n",
    "    '''\n",
    "    Scrapes everything until the stopping condition is met!\n",
    "    '''\n",
    "    while not should_stop(rank_counts) and username_queue.qsize():\n",
    "        # Get the username of the player whose stats we're about to scrape\n",
    "        username = username_queue.get()\n",
    "        \n",
    "        # Try in case something goes wrong\n",
    "        try:\n",
    "            with webdriver.Chrome() as driver:\n",
    "                # Use the /overview page as shown earlier\n",
    "                driver.get(f\"https://tracker.gg/valorant/profile/riot/{username.replace('#', '%23')}/overview\")\n",
    "                page_source = driver.page_source\n",
    "                \n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "            # Find rank first, and only write other stats to CSV if we haven't already hit the limit (5000) for this rank\n",
    "            # Note that we also write the rank as this serves as the label for training our prediction model.\n",
    "            rank = find_rank(soup)\n",
    "            if rank_counts[rank] < 5000:\n",
    "                stats = find_highlighted_stats(soup)\n",
    "                write_to_stats_csv(stats, rank)\n",
    "                rank_counts[rank]+= 1\n",
    "                \n",
    "            # Get ~9 more usernames by looking at the most recent match of this user.\n",
    "            more_usernames = get_usernames_from_match_history(username)\n",
    "            \n",
    "            # Add all these usernames to our queue to continue BFS-ing!\n",
    "            for u in more_usernames:\n",
    "                username_queue.put(u)\n",
    "                \n",
    "        except:\n",
    "            # Could not scrape this username :(\n",
    "            continue\n",
    "            \n",
    "    print(\"Scraped a bucketload of data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b57034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped a bucketload of data!\n"
     ]
    }
   ],
   "source": [
    "# scrape_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df149260",
   "metadata": {},
   "source": [
    "Phew, that took a hot minute. Now that we're done scraping, let's see what our CSV data looks like in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aecf32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84184c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Damage/Round</th>\n",
       "      <th>K/D Ratio</th>\n",
       "      <th>Headshot %</th>\n",
       "      <th>Win %</th>\n",
       "      <th>Wins</th>\n",
       "      <th>KAST %</th>\n",
       "      <th>DDΔ/Round</th>\n",
       "      <th>Kills</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Assists</th>\n",
       "      <th>ACS</th>\n",
       "      <th>KAD Ratio</th>\n",
       "      <th>Kills/Round</th>\n",
       "      <th>First Bloods</th>\n",
       "      <th>Flawless Rounds</th>\n",
       "      <th>Aces</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>12.17</td>\n",
       "      <td>34.89</td>\n",
       "      <td>9</td>\n",
       "      <td>48.65</td>\n",
       "      <td>9</td>\n",
       "      <td>444</td>\n",
       "      <td>404</td>\n",
       "      <td>126</td>\n",
       "      <td>126.99</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.79</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Iron 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102.05</td>\n",
       "      <td>1.15</td>\n",
       "      <td>13.21</td>\n",
       "      <td>33.50</td>\n",
       "      <td>10</td>\n",
       "      <td>53.19</td>\n",
       "      <td>10</td>\n",
       "      <td>460</td>\n",
       "      <td>421</td>\n",
       "      <td>129</td>\n",
       "      <td>114.37</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>78</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Iron 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.77</td>\n",
       "      <td>1.17</td>\n",
       "      <td>13.67</td>\n",
       "      <td>32.05</td>\n",
       "      <td>10</td>\n",
       "      <td>48.92</td>\n",
       "      <td>10</td>\n",
       "      <td>484</td>\n",
       "      <td>454</td>\n",
       "      <td>133</td>\n",
       "      <td>133.68</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Iron 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107.44</td>\n",
       "      <td>1.19</td>\n",
       "      <td>13.68</td>\n",
       "      <td>39.08</td>\n",
       "      <td>10</td>\n",
       "      <td>49.37</td>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>410</td>\n",
       "      <td>157</td>\n",
       "      <td>121.30</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>Bronze 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.16</td>\n",
       "      <td>1.19</td>\n",
       "      <td>15.03</td>\n",
       "      <td>35.04</td>\n",
       "      <td>10</td>\n",
       "      <td>49.97</td>\n",
       "      <td>10</td>\n",
       "      <td>485</td>\n",
       "      <td>416</td>\n",
       "      <td>153</td>\n",
       "      <td>140.47</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.81</td>\n",
       "      <td>84</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>Bronze 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126.92</td>\n",
       "      <td>1.14</td>\n",
       "      <td>14.80</td>\n",
       "      <td>40.81</td>\n",
       "      <td>11</td>\n",
       "      <td>52.28</td>\n",
       "      <td>11</td>\n",
       "      <td>460</td>\n",
       "      <td>467</td>\n",
       "      <td>155</td>\n",
       "      <td>123.93</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.94</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Bronze 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128.07</td>\n",
       "      <td>1.30</td>\n",
       "      <td>13.73</td>\n",
       "      <td>40.70</td>\n",
       "      <td>11</td>\n",
       "      <td>52.10</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>478</td>\n",
       "      <td>146</td>\n",
       "      <td>128.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Silver 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Damage/Round  K/D Ratio  Headshot %  Win %  Wins  KAST %  DDΔ/Round  Kills  \\\n",
       "0        106.00       1.19       12.17  34.89     9   48.65          9    444   \n",
       "1        102.05       1.15       13.21  33.50    10   53.19         10    460   \n",
       "2        103.77       1.17       13.67  32.05    10   48.92         10    484   \n",
       "3        107.44       1.19       13.68  39.08    10   49.37         10    465   \n",
       "4        114.16       1.19       15.03  35.04    10   49.97         10    485   \n",
       "5        126.92       1.14       14.80  40.81    11   52.28         11    460   \n",
       "6        128.07       1.30       13.73  40.70    11   52.10         11    516   \n",
       "\n",
       "   Deaths  Assists     ACS  KAD Ratio  Kills/Round  First Bloods  \\\n",
       "0     404      126  126.99       0.89         0.79            64   \n",
       "1     421      129  114.37       1.01         0.84            78   \n",
       "2     454      133  133.68       0.89         0.85            79   \n",
       "3     410      157  121.30       1.01         0.83            78   \n",
       "4     416      153  140.47       0.95         0.81            84   \n",
       "5     467      155  123.93       1.02         0.94            82   \n",
       "6     478      146  128.64       1.00         0.89            88   \n",
       "\n",
       "   Flawless Rounds  Aces      Rank  \n",
       "0               13     1    Iron 1  \n",
       "1               15     2    Iron 2  \n",
       "2               15     2    Iron 3  \n",
       "3               17     2  Bronze 1  \n",
       "4               17     2  Bronze 2  \n",
       "5               15     2  Bronze 3  \n",
       "6               18     2  Silver 1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'stats.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb4b220",
   "metadata": {},
   "source": [
    "We have all our data sitting nicely in a dataframe! Onto prediction! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
